{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pywt\n",
    "import csv\n",
    "import pickle\n",
    "import keras\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = './dataset/fr/clips/'\n",
    "FEATURES_FILE = 'ultimate_mfcc_features.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(data, axis, length):\n",
    "    pad_width = [(0, 0)] * len(data.shape)\n",
    "    pad_width[axis] = (0, max(0, length - data.shape[axis]))\n",
    "    padded_data = np.pad(data, pad_width, mode='constant', constant_values=0)\n",
    "    return padded_data\n",
    "\n",
    "def get_features(df_in, max_len):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for index in range(0, len(df_in)):\n",
    "        filename = FOLDER_PATH + df_in.path[index]\n",
    "        label = df_in.sentence[index]\n",
    "\n",
    "        # load the file\n",
    "        y, sr = librosa.load(filename)\n",
    "        \n",
    "        # Trim the audio file to remove leading/trailing silence\n",
    "        y, _ = librosa.effects.trim(y)\n",
    "\n",
    "        # Compute MFCC\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)  # n_mfcc: nombre de coefficients MFCC à conserver\n",
    "        \n",
    "        print(mfccs.shape)\n",
    "        \n",
    "        # Pad/truncate MFCCs\n",
    "        if (mfccs.shape[1] < max_len):\n",
    "            pad_width = max_len - mfccs.shape[1]\n",
    "            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            mfccs = mfccs[:, :max_len]\n",
    "        \n",
    "        features.append(mfccs.T)\n",
    "        labels.append(label)\n",
    "\n",
    "    return (features, labels)\n",
    "\n",
    "def preprocess_data(X, y):\n",
    "    print(np.mean(X))\n",
    "    print(np.std(X))\n",
    "    \n",
    "    X = np.array((X - np.mean(X)) / np.std(X))\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "def split_data(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=123)\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('./dataset/fr/*.tsv')\n",
    "\n",
    "dfs = []  # an empty list to store the data frames\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, delimiter='\\t')  # read each csv file\n",
    "    dfs.append(df)\n",
    "    \n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "data = data[['path', 'sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 200\n",
    "\n",
    "if os.path.exists(FEATURES_FILE):\n",
    "    with open(FEATURES_FILE, 'rb') as f:\n",
    "        X, y = pickle.load(f)\n",
    "else:\n",
    "    X, y = get_features(data, max_len)\n",
    "    with open(FEATURES_FILE, 'wb') as f:\n",
    "        pickle.dump((X, y), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.800911\n",
      "101.175186\n"
     ]
    }
   ],
   "source": [
    "X, y = preprocess_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Couche Conv1D\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Couche LSTM pour traiter chaque trame\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(LSTM(32))\n",
    "    \n",
    "    # Couche Dense\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Couche de sortie\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    # Choix de l'optimiseur avec un taux d'apprentissage adapté\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 198, 64)           2560      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 99, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 99, 64)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 99, 64)            33024     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,476\n",
      "Trainable params: 57,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 6s 363ms/step - loss: 1.3895 - accuracy: 0.2493 - val_loss: 1.3879 - val_accuracy: 0.2503\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 4s 330ms/step - loss: 1.3868 - accuracy: 0.2590 - val_loss: 1.3887 - val_accuracy: 0.2513\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 4s 332ms/step - loss: 1.3886 - accuracy: 0.2519 - val_loss: 1.3857 - val_accuracy: 0.2527\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 4s 333ms/step - loss: 1.3861 - accuracy: 0.2604 - val_loss: 1.3863 - val_accuracy: 0.2550\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 4s 339ms/step - loss: 1.3869 - accuracy: 0.2601 - val_loss: 1.3867 - val_accuracy: 0.2522\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 4s 340ms/step - loss: 1.3852 - accuracy: 0.2652 - val_loss: 1.3862 - val_accuracy: 0.2716\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 4s 336ms/step - loss: 1.3833 - accuracy: 0.2699 - val_loss: 1.3836 - val_accuracy: 0.2637\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 4s 340ms/step - loss: 1.3842 - accuracy: 0.2684 - val_loss: 1.3827 - val_accuracy: 0.2744\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 4s 341ms/step - loss: 1.3730 - accuracy: 0.2977 - val_loss: 1.4691 - val_accuracy: 0.2670\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 4s 344ms/step - loss: 1.3947 - accuracy: 0.2649 - val_loss: 1.3869 - val_accuracy: 0.2513\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 4s 339ms/step - loss: 1.3875 - accuracy: 0.2592 - val_loss: 1.3885 - val_accuracy: 0.2513\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 4s 336ms/step - loss: 1.3862 - accuracy: 0.2547 - val_loss: 1.3868 - val_accuracy: 0.2513\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 4s 344ms/step - loss: 1.3861 - accuracy: 0.2565 - val_loss: 1.3869 - val_accuracy: 0.2513\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 4s 343ms/step - loss: 1.3859 - accuracy: 0.2441 - val_loss: 1.3869 - val_accuracy: 0.2448\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 4s 348ms/step - loss: 1.3858 - accuracy: 0.2564 - val_loss: 1.3875 - val_accuracy: 0.2513\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 5s 359ms/step - loss: 1.3860 - accuracy: 0.2609 - val_loss: 1.3871 - val_accuracy: 0.2513\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 5s 358ms/step - loss: 1.3858 - accuracy: 0.2624 - val_loss: 1.3875 - val_accuracy: 0.2513\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 4s 342ms/step - loss: 1.3860 - accuracy: 0.2585 - val_loss: 1.3869 - val_accuracy: 0.2513\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 4s 337ms/step - loss: 1.3858 - accuracy: 0.2575 - val_loss: 1.3869 - val_accuracy: 0.2517\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 4s 341ms/step - loss: 1.3856 - accuracy: 0.2612 - val_loss: 1.3871 - val_accuracy: 0.2522\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 4s 340ms/step - loss: 1.3857 - accuracy: 0.2607 - val_loss: 1.3870 - val_accuracy: 0.2513\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 4s 344ms/step - loss: 1.3856 - accuracy: 0.2610 - val_loss: 1.3871 - val_accuracy: 0.2513\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 4s 342ms/step - loss: 1.3855 - accuracy: 0.2698 - val_loss: 1.3846 - val_accuracy: 0.3441\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 4s 342ms/step - loss: 1.3452 - accuracy: 0.3628 - val_loss: 1.3075 - val_accuracy: 0.3958\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 4s 343ms/step - loss: 1.1765 - accuracy: 0.4262 - val_loss: 1.0729 - val_accuracy: 0.4665\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 5s 352ms/step - loss: 1.0284 - accuracy: 0.4895 - val_loss: 0.9943 - val_accuracy: 0.4887\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 5s 350ms/step - loss: 0.9881 - accuracy: 0.5159 - val_loss: 0.9348 - val_accuracy: 0.5136\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 4s 345ms/step - loss: 0.9278 - accuracy: 0.5310 - val_loss: 0.9056 - val_accuracy: 0.5866\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 4s 346ms/step - loss: 0.8057 - accuracy: 0.6357 - val_loss: 0.6534 - val_accuracy: 0.7058\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 4s 347ms/step - loss: 0.6369 - accuracy: 0.7151 - val_loss: 0.5920 - val_accuracy: 0.7321\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 5s 357ms/step - loss: 0.5541 - accuracy: 0.7650 - val_loss: 0.5083 - val_accuracy: 0.8406\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 5s 351ms/step - loss: 0.5148 - accuracy: 0.8023 - val_loss: 0.4524 - val_accuracy: 0.8527\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 5s 358ms/step - loss: 0.4690 - accuracy: 0.8411 - val_loss: 0.3575 - val_accuracy: 0.9012\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 4s 344ms/step - loss: 0.4077 - accuracy: 0.8690 - val_loss: 0.3213 - val_accuracy: 0.9173\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 4s 348ms/step - loss: 0.3827 - accuracy: 0.8822 - val_loss: 0.2869 - val_accuracy: 0.9136\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 4s 346ms/step - loss: 0.3284 - accuracy: 0.9033 - val_loss: 0.2626 - val_accuracy: 0.9261\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 4s 347ms/step - loss: 0.3079 - accuracy: 0.9104 - val_loss: 0.2321 - val_accuracy: 0.9367\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 4s 347ms/step - loss: 0.2683 - accuracy: 0.9195 - val_loss: 0.2037 - val_accuracy: 0.9446\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 5s 353ms/step - loss: 0.2475 - accuracy: 0.9312 - val_loss: 0.1872 - val_accuracy: 0.9473\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 5s 358ms/step - loss: 0.2293 - accuracy: 0.9324 - val_loss: 0.1525 - val_accuracy: 0.9557\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 5s 355ms/step - loss: 0.1989 - accuracy: 0.9419 - val_loss: 0.1606 - val_accuracy: 0.9538\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 5s 357ms/step - loss: 0.1907 - accuracy: 0.9410 - val_loss: 0.1321 - val_accuracy: 0.9635\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 5s 360ms/step - loss: 0.1700 - accuracy: 0.9475 - val_loss: 0.1391 - val_accuracy: 0.9635\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 5s 355ms/step - loss: 0.1549 - accuracy: 0.9495 - val_loss: 0.1173 - val_accuracy: 0.9663\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 5s 361ms/step - loss: 0.1425 - accuracy: 0.9573 - val_loss: 0.1226 - val_accuracy: 0.9672\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 5s 357ms/step - loss: 0.1387 - accuracy: 0.9578 - val_loss: 0.1102 - val_accuracy: 0.9681\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 5s 360ms/step - loss: 0.1295 - accuracy: 0.9581 - val_loss: 0.1097 - val_accuracy: 0.9672\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 5s 354ms/step - loss: 0.1271 - accuracy: 0.9577 - val_loss: 0.1232 - val_accuracy: 0.9621\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 5s 351ms/step - loss: 0.1238 - accuracy: 0.9587 - val_loss: 0.1257 - val_accuracy: 0.9584\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 5s 358ms/step - loss: 0.1233 - accuracy: 0.9603 - val_loss: 0.1133 - val_accuracy: 0.9695\n"
     ]
    }
   ],
   "source": [
    "# Divisez les données\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = split_data(X, y)\n",
    "\n",
    "# Maintenant, supposons que X a la forme (nombre_d'échantillons, nombre_de_trames, n_mfcc)\n",
    "num_samples, num_frames, n_mfcc = X_train.shape\n",
    "input_shape = (num_frames, n_mfcc)\n",
    "\n",
    "# Convertir les étiquettes en format catégorique\n",
    "num_classes = 4\n",
    "y_train = to_categorical(y_train - 1, num_classes)\n",
    "y_val = to_categorical(y_val - 1, num_classes)\n",
    "y_test = to_categorical(y_test - 1, num_classes)\n",
    "\n",
    "# Créez le modèle\n",
    "model = create_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "# Ajoutez le critère d'arrêt précoce à la liste des callbacks pour l'entraînement\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=512, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 2s 9ms/step - loss: 0.0565 - accuracy: 0.9803\n",
      "91/91 [==============================] - 1s 9ms/step - loss: 0.0636 - accuracy: 0.9799\n",
      "91/91 [==============================] - 1s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "# Évaluez le modèle\n",
    "TrainLoss, Trainacc = model.evaluate(X_train, y_train)\n",
    "TestLoss, Testacc = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion_matrix:  tf.Tensor(\n",
      "[[671   1   8  11]\n",
      " [  2 741   0   3]\n",
      " [  7   0 720   0]\n",
      " [ 22   3   1 697]], shape=(4, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print('Confusion_matrix: ', tf.math.confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))\n",
    "\n",
    "# Sauvegardez le modèle\n",
    "model.save(\"98ultimatemodel.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
