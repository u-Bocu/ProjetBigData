{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from keras.optimizers import Adam\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM, Dense, Dropout, Conv2D, Flatten, Reshape, MaxPooling1D\n",
    "from keras.layers import Conv1D, LSTM, TimeDistributed\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FOLDER_PATH = './dataset/fr/clips/'\n",
    "FEATURES_FILE = 'matthieu_features.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(data, axis, length):\n",
    "    pad_width = [(0, 0)] * len(data.shape)\n",
    "    pad_width[axis] = (0, max(0, length - data.shape[axis]))\n",
    "    padded_data = np.pad(data, pad_width, mode='constant', constant_values=0)\n",
    "    return padded_data\n",
    "\n",
    "\n",
    "def get_features(df_in):\n",
    "    features = []\n",
    "    labels = []\n",
    "    max_len = 270000\n",
    "\n",
    "    for index in range(0, len(df_in)):\n",
    "        filename = FOLDER_PATH + df_in.path[index]\n",
    "        label = df_in.sentence[index]\n",
    "\n",
    "        # load the file\n",
    "        y, sr = librosa.load(filename)\n",
    "        \n",
    "        cA, cD = pywt.dwt(y, 'haar')\n",
    "        \n",
    "        data = np.concatenate((cA, cD), axis=0)\n",
    "        \n",
    "        print(data)\n",
    "        print(len(data))\n",
    "\n",
    "        data = np.pad(data, (0, max_len - len(data)))\n",
    "        features.append(data)\n",
    "        labels.append(label)\n",
    "\n",
    "    output = np.concatenate(features, axis=0)\n",
    "    return (features, labels)\n",
    "\n",
    "\n",
    "def preprocess_data(X, y):\n",
    "    X = np.array((X - np.min(X)) / (np.max(X) - np.min(X)))\n",
    "    X = X / np.std(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def split_data(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=123)\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val\n",
    "\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = keras.Sequential()\n",
    "    model.add(Conv1D(64, kernel_size=5, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(14, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./dataset/fr/test.tsv', delimiter='\\t')\n",
    "data = data[['path', 'sentence']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.exists(FEATURES_FILE):\n",
    "    with open(FEATURES_FILE, 'rb') as f:\n",
    "        X, y = pickle.load(f)\n",
    "else:\n",
    "    X, y = get_features(data)\n",
    "    with open(FEATURES_FILE, 'wb') as f:\n",
    "        pickle.dump((X, y), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5685, 270000)\n",
      "(5685,)\n",
      "5685\n",
      "5685\n"
     ]
    }
   ],
   "source": [
    "X, y = preprocess_data(X, y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.07 GiB for an array with shape (1066, 270000) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, X_val, y_train, y_test, y_val \u001b[39m=\u001b[39m split_data(X, y)\n\u001b[0;32m      3\u001b[0m input_shape \u001b[39m=\u001b[39m (\u001b[39mNone\u001b[39;00m, \u001b[39m270000\u001b[39m)\n\u001b[0;32m      4\u001b[0m X_train \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mreshape((\u001b[39m1\u001b[39m, X_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], X_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]))\n",
      "Cell \u001b[1;32mIn[11], line 44\u001b[0m, in \u001b[0;36msplit_data\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msplit_data\u001b[39m(X, y):\n\u001b[0;32m     43\u001b[0m     X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m123\u001b[39m, stratify\u001b[39m=\u001b[39my)\n\u001b[1;32m---> 44\u001b[0m     X_train, X_val, y_train, y_val \u001b[39m=\u001b[39m train_test_split(X_train, y_train, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m123\u001b[39;49m)\n\u001b[0;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m X_train, X_test, X_val, y_train, y_test, y_val\n",
      "File \u001b[1;32mc:\\Users\\mremond\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2585\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2581\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m   2583\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39msplit(X\u001b[39m=\u001b[39marrays[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mstratify))\n\u001b[1;32m-> 2585\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\n\u001b[0;32m   2586\u001b[0m     chain\u001b[39m.\u001b[39;49mfrom_iterable(\n\u001b[0;32m   2587\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m arrays\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mremond\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2587\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2581\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m   2583\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39msplit(X\u001b[39m=\u001b[39marrays[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mstratify))\n\u001b[0;32m   2585\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   2586\u001b[0m     chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[1;32m-> 2587\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mremond\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\__init__.py:356\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[39mreturn\u001b[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m    355\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 356\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_indexing(X, indices, indices_dtype, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m    357\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     \u001b[39mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[1;32mc:\\Users\\mremond\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\__init__.py:185\u001b[0m, in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    184\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m--> 185\u001b[0m \u001b[39mreturn\u001b[39;00m array[key] \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m array[:, key]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.07 GiB for an array with shape (1066, 270000) and data type float32"
     ]
    }
   ],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = split_data(X, y)\n",
    "\n",
    "input_shape = (None, 270000)\n",
    "X_train = X_train.reshape((1, X_train.shape[0], X_train.shape[1]))\n",
    "X_val = X_val.reshape((1, X_val.shape[0], X_val.shape[1]))\n",
    "y_train = y_train.reshape((1, y_train.shape[0]))\n",
    "y_val = y_val.reshape((1, y_val.shape[0]))\n",
    "\n",
    "num_classes = 14  # Remplacez par le nombre de classes réel\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_val = to_categorical(y_val, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "max_seq_length = X_train.shape[1]  # Longueur maximale de séquence\n",
    "y_train = y_train[:, :max_seq_length, :]\n",
    "y_val = y_val[:, :max_seq_length, :]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "model = create_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=254, validation_data=(X_val, y_val))\n",
    "\n",
    "TrainLoss, Trainacc = model.evaluate(X_train, y_train)\n",
    "TestLoss, Testacc = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Confusion_matrix: ', tf.math.confusion_matrix(y_test, np.argmax(y_pred, axis=1)))\n",
    "\n",
    "model.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
